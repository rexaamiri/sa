1/8
00:00:00 In this section, the speaker, Justin Zeltzer from ZStatistics.com, discusses survival analysis and its applications across various fields. The topic centers around measuring survival time, AKA time to event analysis, which is concerned with the time that an event takes to occur after an exposure, such as a diagnosis. Survival analysis can be used to assess the progression of a disease like cancer, the survival of a company after a stock market shock or even survival rates of social institutions like marriage. The speaker emphasizes that survival analysis is essential in assessing survival time and its applications are diverse.
00:05:00 for further discussion, we need to collect data on the survival rates of people diagnosed with lung cancer and analyze this data to study survival rates and the time since diagnosis. To analyze the data, we reset the survival times, so that they start at the same point, in order to calculate and plot survival rates on a Kaplan-Meier curve, which represents the non-parametric curve of survival rates over time, based on the data. We can visualize the survival rates of patients using this curve, which helps to understand the proportion of patients surviving over a certain timeframe. The applications of survival analysis are vast, and it can be applied in various fields, including health, engineering, and finance.
00:10:00 In this section, the speaker introduces survival analysis as a statistical method used to assess the time it takes for an event to occur. Survival analysis can be applied in various fields, including healthcare, manufacturing, finance, and social contexts. It is not limited to assessing negative events like death but can also be used to measure positive events like divorce or the time it takes for a couple to have their second child after the first. In sports, survival analysis can be used to determine the optimum time for a substitution in soccer. The video series will continue with a discussion on censoring, a crucial concept for survival analysis.

2/8
00:00:00 In this section, the concept of censoring and truncation in survival analysis is discussed. Censoring occurs when the exact time to an event is unknown for an included observation. There are three types of censoring: left censoring, interval censoring, and right censoring. Left censoring refers to knowing that the time to event is less than a specific value, interval censoring refers to knowing the time to event falls between two values, and right censoring refers to knowing that the time to event is greater than a specific value. An example of right censoring is given in a study on estimating survival time after a diagnosis of pancreatic cancer, where individuals who did not die by the end of the study period were censored and their time to event is uncertain.
00:05:00 In this section, the video explains different types of censoring and truncation in survival analysis. Censoring occurs when there is incomplete information about the exact time of an event, such as death. Left censoring happens when individuals have already experienced the event before entering the study, while right censoring occurs when there is no information about the event beyond a certain point. Truncation, on the other hand, refers to observations being excluded from the data set based on their time to event. Left truncation occurs when observations with short times to event are excluded, while right truncation excludes observations with long times to event. The video clarifies that the term "truncation" is often used to describe the exclusion of observations in the data set as a whole rather than referring to individual observations.
00:10:00 In this section, the video discusses two types of truncation in survival analysis: left truncation and right truncation. Left truncation occurs when the shortest survival times are missing from the data set, which can introduce bias. An example of left truncation is the study on animal neonates, where neonates with very short survival times might not have been available for sampling. On the other hand, right truncation occurs when the data set is biased towards individuals who experience an event quickly. An example of right truncation is the study on the time to development of AIDS, where individuals with long times to event were not included in the study since they had not yet developed AIDS by the time it finished. Accounting for truncation is important in survival analysis to ensure accurate estimation of survival times.

3/8
00:00:00 In this section of the YouTube video titled "Life Tables - [Survival Analysis 3/8]" by Justin Zeltzer from ZStatistics.com, the intuition behind life tables and their peculiarities are explained. Life tables illustrate the pattern of survivorship of a population by considering the probability of death at each consecutive age. The concept is illustrated through a chart showing the percentage of people still alive at different ages for females and males, emphasizing how survivorship drops off with age and how life tables can be used to compare populations. Although the name "life tables" may seem unusual after seeing a chart, the title comes from the fact that there is a table of data beneath the chart displaying the proportion surviving to age x, or the number out of a hundred thousand surviving to each age, which can be used to find various statistical measures such as medians, quartiles, and mean age at death. The inputs required for life tables are the population by age group or individual ages and deaths in each age group, while the outputs include the aggregate survival given the letter
00:05:00 In this section of the YouTube video titled "Life Tables - [Survival Analysis 3/8]," the speaker explains the differences between survival functions and conditional life expectancies, using the example of period life tables for the year 2019. However, the data does not represent the trajectory of survival for people born that year, but rather a collection of data for various cohorts, each with different environmental factors influencing their survival. The speaker then discusses the use of cohort life tables, which require collecting data from particular birth cohorts and following their life spans over time. To find the projected cohort life table for people born today, statisticians adjust the periodic life table by considering changes in life expectancy, a complex process that is not covered in detail in the video. The section concludes with instructions on calculating survival curves using Excel, starting with calculating the central death rate and conditional probability of death
00:10:00 In this section of the video, the concept of life tables and life expectancy is further explained. People who are 364 days old are considered six months old in terms of calendar age, but not all of them are still alive. To account for this, the conditional probability of death is calculated, which is different from the central death rate due to the fact that some people have already died and are not counted in the population. The conditional probability of survival, p, is then discussed, and the number of people surviving to a certain age is calculated using the formula: number surviving to age x = previous number surviving to the previous age * conditional probability of surviving that age. The process is repeated for age one and onward, and the proportion of people surviving to a certain age is determined by dividing the number of people surviving to that age by the initial population of 100,000. The final column in the life table, capital L, represents the total person years lived at a certain age. This is calculated by taking an average of the number of people who started at that age and the number of people alive at the next age
00:15:00 In this section of the YouTube video titled "Life Tables - [Survival Analysis 3/8]", the presenter explains how to calculate the average number of person-years lived at a specific age, starting from age one, and how to sum up these values to find the total years lived from age zero onwards. He also presents the concept of total life expectancy, which is the total number of years lived from birth for a given population, and conditional life expectancy, which indicates the expected remaining years of life for individuals at a particular age. The presenter then introduces disability-free life expectancy, which reflects the number of years lived without significant disability, by multiplying the person-years lived at a specific age by one minus the proportion of people with a disability at that age
00:20:00 In this section of the "Life Tables" YouTube video, the speaker explains how to calculate Disability-Free Life Expectancy (DFLE). He sums up the "Person Years Lived Without Disability" column and divides it by the number of surviving individuals to obtain the DFLE for a particular age and gender. The speaker emphasizes that this metric provides a healthier perspective on life expectancy and can be compared between different populations. However, he acknowledges various assumptions made during the calculation, such as defining disability. Overall, DFLE offers an insightful approach to understanding the quality of life expectancy instead of focusing solely on lifespan.

4/8
00:00:00 In this section, the video introduces Kaplan-Meier curves as a commonly used estimator in survival analysis. The video explains that Kaplan-Meier estimation is a non-parametric estimator of survival, meaning it does not rely on any specific parameters or assumptions. Instead, it uses the specific data set to create the estimator. The video then provides an example of using Kaplan-Meier estimation to determine the survival time of wombats infected with mange.
00:05:00 In this section, the speaker discusses the concept of censoring in survival analysis. They explain that even if a subject does not die during the observation period, they are still included in the dataset and their survival time is recorded as the duration of the monitoring period. The speaker also introduces the Kaplan-Meier curve and explains how to calculate survival estimates using the formula that involves the number at risk and the number that died at each time period. They demonstrate the application of this formula using a hypothetical example and highlight the progressive construction of the Kaplan-Meier curve.
00:10:00 In this section, the speaker explains the concept of censoring in survival analysis and how it affects the calculation of survival rates. They demonstrate how the survival curve is extended when a wombat is censored instead of dying. The speaker also emphasizes the importance of multiplying the current survival fraction with the previous survival value, rather than multiplying each fraction individually. They show how this approach affects the shape of the survival curve. The speaker then discusses how to find the median survival time and percentiles on the survival curve. They mention that confidence intervals are commonly used in survival analysis and briefly touch on the topic, recommending further exploration for those interested in understanding the calculations.
00:15:00 In this section, the speaker explains how to calculate confidence intervals for survival analysis. The method involves finding the variance of the log of the survival rate and then constructing a confidence interval based on this variance. The speaker goes through the mathematical steps involved in deriving the formula for the confidence interval and provides a table to demonstrate the calculation process for different time periods.
00:20:00 In this section, the speaker discusses the calculation of the log of the survival and the variance of the log of survival in the context of Kaplan-Meier curves. They explain that the upper limit for the log of survival cannot be greater than zero, as it would imply a survival rate of more than 100 percent. The speaker also mentions that there are different versions of confidence intervals for survival curves, including a double log or log-log transformation. Additionally, they introduce the log-rank test, which assesses whether the survival curves of different sub-populations are significantly different from each other. They provide an example of comparing the survival curves of male and female wombats and explain that the null hypothesis in the log-rank test is that the survival curves are equal.
00:25:00 In this section, the speaker discusses how to find the expected number of deaths for males and females in each time period using the proportion of each sex at risk and the number of deaths. They explain the calculation of the chi-squared statistic to compare the observed and expected numbers of deaths for males and females. The speaker demonstrates that, in this specific example, there is not enough evidence to conclude that male and female survival curves are different based on the chi-squared test. They also mention a slightly alternative chi-squared calculation used in R.
00:30:00 In this section, the speaker discusses the process of using R software to conduct survival analysis. They explain how to install the necessary packages and load in the data. The speaker demonstrates how to create a fit object and generate a summary of the survival curves. They also showcase how to plot the survival curve and the corresponding confidence intervals. Additionally, the speaker mentions the option to use a log-log version of the survival plot, which eliminates the need to truncate the confidence intervals to reach a maximum of 100% survival probability. They note that some textbooks prefer this log-log version over the regular log version.
00:35:00 In this section, the speaker discusses the use of log-log plots in survival analysis and explains that they are the most preferred option for analyzing large datasets. They then introduce a new analysis based on sex and show how to create a plot split by sex using the 'gg surf plot' function. Finally, they demonstrate how to test whether males and females are different using the 'serve diff' function, which yields a chi-squared statistic of 4.2. The speaker concludes by encouraging viewers to share and subscribe to their content while providing access to the code used in the video.

5/8
00:00:00 In this section of the Survival Analysis video series, the speaker introduces the concepts of survival and Hazard functions. He recaps the previous video's introduction to the survival curve, which is represented by a Kaplan-Meier estimator, and explains that the goal is to create a survival function that better reflects the true nature of survival as time progresses. The speaker begins by discussing the relationship between the cumulative distribution function (CDF) and the survival function. In the example shown, individuals diagnosed with a disease named "disease X" are dying uniformly within a five-year window of diagnosis. The CDF represents the proportion of people who have died at certain numbers of years from diagnosis, while the survival function shows how many people have survived. The survival function is almost the reverse of the cumulative distribution function. The speaker then explains the probability density function, which is the gradient of the cumulative distribution function in this example. He notes that this simplified example has a uniform probability density function because everyone dies within the five-year window. He emphasizes that they will change this example later in the video. To find the proportion of people dying within specific time intervals, one can calculate the area under the probability density function curve. For example, the area under the curve from 0 to 3 represents the proportion of people who have died within three years of being diagnosed with the disease. The speaker concludes this section by reiterating that the area under the probability density function curve must sum to one, just like the cumulative distribution function. He then moves on to discussing Hazard functions and their relationship with the survival and probability density functions
00:05:00 In this section of the video, the survivor function, hazard function, and their relation are discussed in the context of survival analysis. The survivor function, giving a value of 0.6, indicates that 60 out of 100 people have survived after two years. The hazard function, which represents the instantaneous risk of the event occurring, shows an increasing risk of death as time passes. At three years, the hazard function equals 0.5, suggesting that half of the people who have survived up to that point will likely die within the following year. The hazard function is calculated by dividing the probability density function by the survival function, indicating a relationship between the two functions. The hazard function can be described as a measure of the number of deaths per year, even though individuals can only die once. The cumulative hazard function, which represents the total risk of an event up to a specific point, is the area underneath the hazard function up to that point
00:10:00 In this section of the video, the speaker explains the concept of cumulative hazard functions in survival analysis. The cumulative hazard measures the accumulation of risk or hazard of an event, such as death, over time. At time zero, the cumulative hazard is zero, as no risk has accumulated. By integrating the hazard function between time zero and any given time T, we obtain the cumulative hazard at that time. This integrated area under the curve represents the total number of deaths that have occurred from time zero to time T. The speaker then explains that the cumulative hazard function is related to other functions, such as the survival function, through integration and differentiation. The hazard function is the probability density function divided by the survival function, while the survival function is one minus the cumulative distribution function. The negative log of the survival function is equivalent to the cumulative hazard function. The speaker intends to demonstrate this relationship using Microsoft Excel
00:15:00 In this section of the YouTube video titled "Hazard and Survival Functions - [Survival Analysis 5/8]", the creator explains various probability density functions, including uniform, exponential, and Weibull, and their corresponding hazard and survival functions. For the exponential probability density function, the hazard function maintains a constant value, allowing for flexibility in creating various curves. The creator emphasizes the use of exponential functions in reality due to their versatility. The video also covers the Weibull probability density function, which provides additional application in engineering and engineering-related fields, and allows for customization with different parameters. The creator encourages the audience to explore these functions further and offers resources on the zedstatistics.com website. The video concludes by inviting viewers to like, subscribe, and consider donating to an education-based charity

6/8


7/8


8/8


